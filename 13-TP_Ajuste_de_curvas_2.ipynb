{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N°13 - Regresión Logística\n",
    ">Información e imagenes obtenidas de presentaciones de: Eric Eaton, Iassonas Kokkinos y Vivek Srikumar\n",
    "\n",
    "Supongamos que quisieramos implementar un modelo para clasificar objetos de dos clases basado en probabilidades. Esto es:\n",
    "\n",
    "$0\\leq p(clase) \\leq 1$\n",
    "\n",
    "$p(clase)+p(\\neg clase) = 1$\n",
    "\n",
    "Si quieramos utilizar un modelo lineal nos encontrariamos con la siguiente situación:\n",
    "\n",
    "![classification_linear_fit](img/classification_linear_fit.png)\n",
    "\n",
    "Si analizamos graficamente la función de costo cuadratica:\n",
    "\n",
    "![classification_quadratic_loss](img/classification_quadratic_loss.png)\n",
    "\n",
    "Podemos ver que la funcion de costo asigna un peso muy grande a los elementos del dataset que estan mas alegajos de la frontera de deción, situación no deseable para un clasificador binario. Ademas, la siguiente condición, no se cumple:\n",
    "\n",
    "$$p(clase)+p(\\neg clase) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística (Logistic Regression)\n",
    "\n",
    "![logistic_regression](img/logistic_regression.png)\n",
    "\n",
    "### Función de costo:\n",
    "\n",
    "$\\ell(\\theta)=-\\sum_{i=1}^n[y_i\\;log\\;h_{\\theta}(x_i)+(1-y_i)\\;log\\;(1-h_{\\theta(x_i)})]$ (Entropía cruzada - Cross Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbral de decisión (Decision threshold)\n",
    "Para determinar si un punto $x_i$ pertenece a la clase evaluada hay que determinar un umbral de decision. \n",
    "Una elección común es:\n",
    "- predecir y=1 si $h_{\\theta}\\geq 0.5$\n",
    "- predecir y=0 si $h_{\\theta} < 0.5$\n",
    "\n",
    "Pero puede tomar otros valores dependiendo del problema.\n",
    "\n",
    "![function_threshold](img/function_threshold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Límite de decisión no lineal (Non-linear Decision boundary)\n",
    "En el caso de requirir limetes de decisión no lineal, se puede utilizar (al igual que regresión lineal comun) la tecnica expación de función.\n",
    "\n",
    "![function_expansion](img/function_expansion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de costo con factor de regularización\n",
    "\n",
    "Hay casos donde no queremos que los coefientes de nuestro predictor lineal sean muy grandes. Para evitar esto, podemos agregar un termino de penalización en la función de costo, que penalize (elevando el costo de la función) los coeficientes muy grandes o muy chicos.\n",
    "\n",
    "$\\ell(\\theta)=-\\sum_{i=1}^n[y_i\\;log\\;h_{\\theta}(x_i)+(1-y_i)\\;log\\;(1-h_{\\theta(x_i)})] + \\lambda\\sum_{j=1}^d\\theta_j^2$\n",
    "\n",
    "![classification_log_loss](img/log_loss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso de gradiente en Regresión Logística\n",
    "\n",
    "1. Inicializar $\\theta_d$\n",
    "2. Repetir hasta alcanzar un umbrarl de convergencia:\n",
    "\n",
    "    $\\theta_0\\leftarrow\\theta_0-\\eta[\\sum_{i=1}^n(h_{\\theta}(x^{(i)})-y^{(i)})]$ (bias)\n",
    "    \n",
    "    $\\theta_j\\leftarrow\\theta_j-\\eta[\\sum_{i=1}^n(h_{\\theta}(x^{(i)})-y^{(i)})x_j^{(i)}]$ (sin regularización)\n",
    "    \n",
    "    $\\theta_j\\leftarrow\\theta_j-\\eta[\\sum_{i=1}^n(h_{\\theta}(x^{(i)})-y^{(i)})x_j^{(i)}-\\frac{\\lambda}{n}\\theta_j]$ (con regularización)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "1. Implementar Regreción Logística utilizando descenso de gradiente como clasificador con el dataset sintetico utilizado en el TP07.\n",
    "    1. Comparar desempeño con y sin termino de regularización en los parametros.\n",
    "    2. Evaluar la calidad de la predicción utilizando la metrica \"Accuracy\" vista en el TP07 \n",
    "    3. Graficar resultados\n",
    "    \n",
    "Utilizar Cross-Validation para determinar el mejor $\\eta$ y $\\lambda$ a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística Multi-Clase\n",
    "¿Es posible utilizar un clasificador binario para construir un clasificador multiclase?\n",
    "\n",
    "Vamos a utilizar un de las posibles tecnicas: **One-vs-all**\n",
    "\n",
    "**asunción:** Cada clase tiene que ser linealmente separable de todas las demas.\n",
    "\n",
    "**Aprendizaje:** Dado un dataset $D={(x_i,y_i)}$\n",
    "* $x\\in\\mathfrak{R}^n$\n",
    "* $y\\in\\{1,2,\\cdots,K\\}$ \n",
    "* Crear $K$ clasificadores binarios\n",
    "* Entrenar cada clasificador $k_i$ \n",
    "    * **Ejemplos positivos:** Puntos en $D$ con la etiqueta $k$\n",
    "    * **Ejemplos negativos:** Todos los puntos en $D$ con etiquetas distintas a $k$\n",
    "* **Predicción:** ''El ganador se lleva todo\"\n",
    "    * El predictor $k$ con el mayor porcentaje gana en la predicción de la clase.\n",
    "\n",
    "![one-vs-all](img/one-vs-all.png)\n",
    "\n",
    "**Beneficios:**\n",
    "* Facil de implementar\n",
    "\n",
    "**Problemas:**\n",
    "* No tiene justificación téorica\n",
    "* Problemas de calibración\n",
    "    * Se comparan predicciónes de $K$ clasificadores entrenados independientemente. No hay para que los valores retornados por cada predictor se encuentren en el mismo rango. \n",
    "    * Por ejemplo: Un predictor $k_i$ puede retornar porcentajes extremadamente alto para la clase que detecta haciendo que siempre posea el porcentaje mas alto de la predicción multiclase global.\n",
    "\n",
    "![one-vs-all-issue](img/one-vs-all-issue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "Implementar Regresión Logística multiclase (One vs All) con dataset Iris utilizado en el TP07 utilizando termino de regularización en la funcion de costo.\n",
    "\n",
    "Utilizar Cross-Validation para determinar el mejor $\\eta$ y $\\lambda$ a utilizar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
